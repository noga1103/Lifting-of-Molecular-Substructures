Mon Nov 18 00:41:09 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3090        On  |   00000000:27:00.0 Off |                  N/A |
| 74%   69C    P2            218W /  350W |   12589MiB /  24576MiB |     32%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA GeForce RTX 3090        On  |   00000000:28:00.0 Off |                  N/A |
| 64%   63C    P2            182W /  350W |    9423MiB /  24576MiB |     94%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA GeForce RTX 3090        On  |   00000000:43:00.0 Off |                  N/A |
| 62%   63C    P2            182W /  350W |    9411MiB /  24576MiB |     79%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA GeForce RTX 3090        On  |   00000000:44:00.0 Off |                  N/A |
| 30%   40C    P5             44W /  350W |       2MiB /  24576MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA GeForce RTX 3090        On  |   00000000:A3:00.0 Off |                  N/A |
| 55%   59C    P2            195W /  350W |    9425MiB /  24576MiB |     80%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA GeForce RTX 3090        On  |   00000000:A4:00.0 Off |                  N/A |
| 39%   47C    P2            179W /  350W |    9421MiB /  24576MiB |     93%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA GeForce RTX 3090        On  |   00000000:C3:00.0 Off |                  N/A |
| 38%   48C    P2            189W /  350W |    9409MiB /  24576MiB |     82%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA GeForce RTX 3090        On  |   00000000:C4:00.0 Off |                  N/A |
| 75%   71C    P2            206W /  350W |    9431MiB /  24576MiB |     78%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   1092459      C   python                                      12582MiB |
|    1   N/A  N/A   4040512      C   python                                       9290MiB |
|    2   N/A  N/A    389788      C   python                                       9278MiB |
|    4   N/A  N/A    271841      C   python                                       9292MiB |
|    5   N/A  N/A    271974      C   python                                       9288MiB |
|    6   N/A  N/A    351893      C   python                                       9276MiB |
|    7   N/A  N/A    347626      C   python                                       9298MiB |
+-----------------------------------------------------------------------------------------+
Running job 99253 with config: configs/param_sweep/CCXN_lr_1e-02.json
{
    "name": "CCXN_lr_1e-02",
    "model": "CCXNModel",
    "hidden_dimensions": 100,
    "n_layers": 20,
    "learning_rate": 0.01,
    "num_epochs": 100,
    "test_interval": 5,
    "test_size": 0.2,
    "dataset": "zinc_small",
    "gradient_accumulation_steps": 100,
    "epoch_size": 10000
}
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: jhorovitz (jhorovitz-tel-aviv-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.7
wandb: Run data is saved locally in /home/dcor/jh1/code/gnn/wandb/run-20241118_004121-il0b23ue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 99253 - configs/param_sweep/CCXN_lr_1e-02.json
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jhorovitz-tel-aviv-university/GNN
wandb: üöÄ View run at https://wandb.ai/jhorovitz-tel-aviv-university/GNN/runs/il0b23ue
Parameters: 410603
Loaded dataset/pkl_data/zinc_0.pkl in 1.59429s
adding graph matrices took: 33.756949s
Data loaded: 20788
Starting training...
Epoch 1/100 Training:   0%|          | 0/10000 [00:00<?, ?graph/s]Epoch 1/100 Training:   0%|          | 0/10000 [00:00<?, ?graph/s]
Traceback (most recent call last):
  File "/home/dcor/jh1/code/gnn/train.py", line 211, in <module>
    main()
  File "/home/dcor/jh1/code/gnn/train.py", line 207, in main
    train_model(model, train_data, test_data, config, output_dir=output_dir)
  File "/home/dcor/jh1/code/gnn/train.py", line 115, in train_model
    y_hat = model(graph)
            ^^^^^^^^^^^^
  File "/home/dcor/jh1/miniforge3/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dcor/jh1/miniforge3/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dcor/jh1/code/gnn/train/ccxn.py", line 40, in forward
    x_0, x_1, x_2 = self.base_model(x_0, x_1, adjacency_0, incidence_2_t, x_2=x_2)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dcor/jh1/miniforge3/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dcor/jh1/miniforge3/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: CCXN.forward() got an unexpected keyword argument 'x_2'
[1;34mwandb[0m: üöÄ View run [33m99253 - configs/param_sweep/CCXN_lr_1e-02.json[0m at: [34mhttps://wandb.ai/jhorovitz-tel-aviv-university/GNN/runs/il0b23ue[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241118_004121-il0b23ue/logs[0m
slurmstepd: error: _cgroup_procs_check: failed on path (null)/cgroup.procs: No such file or directory
slurmstepd: error: Cannot write to cgroup.procs for (null)
slurmstepd: error: Unable to move pid 1149757 to init root cgroup (null)
